# -*- coding: utf-8 -*-
"""OCR Tesseract AZE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10x0zhPjvZPhc8B3VP32pfRqa0rl6BIrL

# Tesseract 4.0.0
This is an example of Tesseract OCR for different languages including Azerbaijani.
For Latin-based languages, the existing model data provided has been trained on about 400000 text lines spanning about 4500 fonts. [Tesseract Pretrained Models for different languages including AZE and AZE Cryl](https://github.com/tesseract-ocr/tessdata_fast)

## Libraries
Note: PIL can cause some headaches depending on which installation you previously had.
"""

!sudo apt install tesseract-ocr
!pip install pytesseract
!apt-get install poppler-utils 
!pip install pdf2image
import cv2
import pytesseract
from pytesseract import Output
try:
    from PIL import Image
except ImportError:
    import Image
import matplotlib.pyplot as plt
from pdf2image import convert_from_path, convert_from_bytes
import re
from google.colab.patches import cv2_imshow

!cat /etc/*release
print(f'Using {pytesseract.get_tesseract_version()}')

"""## Read Images"""

from google.colab import files
files.upload()

image_path = '/content/sened_2.png'
extractedInformation = pytesseract.image_to_string(Image.open(image_path))

print(extractedInformation)

img = cv2.imread(image_path)
d = pytesseract.image_to_data(img, output_type= Output.STRING)

plt.figure(figsize=(8, 6))
plt.imshow(img, aspect='auto')

"""## Read PDFs"""

images = convert_from_path('ALY.pdf')
print ("Number of pages: " + str(len(images)))
for i in range (len(images)):
  if i > 2:
    continue
  print ("Page NÂ°" + str(i+1) + "\n")
  print(pytesseract.image_to_string(images[i]))

images = convert_from_bytes(open('ALY.pdf', 'rb').read(), size=800)
display(images[0])

"""## Simple Image Cleaning Techniques"""

def grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
 
# noise removal
def remove_noise(image):
    return cv2.medianBlur(image,3)
  
# thresholding
def thresholding(image):
    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
 
# dilation
def dilate(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.dilate(image, kernel, iterations = 1)
     
# erosion
def erode(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.erode(image, kernel, iterations = 1)
 
# opening - erosion followed by dilation
def opening(image):
    kernel = np.ones((5,5),np.uint8)
    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
 
# canny edge detection
def canny(image):
    return cv2.Canny(image, 100, 200)
 
# skew correction
def deskew(image):
    coords = np.column_stack(np.where(image > 0))
    angle = cv2.minAreaRect(coords)[-1]
    if angle < -45:
        angle = -(90 + angle)
    else:
        angle = -angle
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return rotated
 
# template matching
def match_template(image, template):
    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)

from google.colab import files
files.upload()

image_original = cv2.imread('/content/french.png')
print(pytesseract.image_to_string(image_original))
plt.imshow(image_original,'gray')

retouche3 = remove_noise(image_original)
print(pytesseract.image_to_string(retouche3))
plt.imshow(retouche3)

retouche4 = thresholding(grayscale(remove_noise(image_original)))
print(pytesseract.image_to_string(retouche4))
plt.imshow(retouche4,'gray')

image_original.shape

hImg, wImg = retouche4.shape
boxes = pytesseract.image_to_boxes(image_original)

for b in boxes.splitlines():
  b = b.split(' ')
  x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4])
  img = cv2.rectangle(retouche4, (x, hImg - y), (w,hImg - h), (0, 255, 0), 2)
  # img = cv2.putText(retouche4, b[0], (x, hImg - y), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 2)
plt.imshow(img, 'gray')

idcard = cv2.imread(image_path, cv2.COLOR_BGR2GRAY)
gray = cv2.cvtColor(idcard, cv2.COLOR_BGR2GRAY)
denoised = cv2.fastNlMeansDenoising(gray, None, 3, 7, 21)
plt.imshow(denoised)

"""# Invoice Bounding boxes"""

invoice = cv2.imread("invoice-sample.jpg")
plt.figure(figsize = (8, 10))
plt.imshow(invoice, 'gray', aspect = 'auto')
d = pytesseract.image_to_data(invoice, output_type=Output.DICT)

d = pytesseract.image_to_data(invoice, output_type=Output.DICT)
print(d.keys())

number_of_boxes = len(d['text'])
for i in range(number_of_boxes):
  if d['conf'][i] > 60: 
    x, y, w, h = d['left'][i], d['top'][i], d['width'][i], d['height'][i]
    img = cv2.rectangle(invoice, (x, y), (x+w, y+h), (0, 255, 0), 2)
plt.figure(figsize = (8, 10))
plt.imshow(img, 'gray', aspect = 'auto')

cv2_imshow(img)

"""## Template matching: Date Pattern"""

date_pattern = '^(0[1-9]|[12][0-9]|3[01])/(0[1-9]|1[012])/(19|20)\d\d$'

for i in range(number_of_boxes):
  if d['conf'][i] > 60:
    if re.match(date_pattern, d['text'][i]):
      x, y, w, h = d['left'][i], d['top'][i], d['width'][i], d['height'][i]
      date = cv2.rectangle(invoice, (x, y), (x+w, y+h), (0, 255, 0), 2)
plt.imshow(date, 'gray')

"""## Text Orientation"""

osd = pytesseract.image_to_osd(invoice)
print(osd)
angle = re.search('(?<=Rotate: )\d+', osd).group(0)
print("angle: ", angle)

"""## Tesseract for Languages: AZE"""

!sudo apt install tesseract-ocr-tur
# !sudo apt install tesseract-ocr-aze

files.upload()

img = cv2.imread("/content/sened_1.jpg")

custom_config = r'-l aze --psm 6'

"""### Automatically detect the language
This module again, does not detect the language of text using an image but needs string input to detect the language from. The best way to do this is by first using tesseract to get OCR text in whatever languages you might feel are in there, using langdetect to find what languages are included in the OCR text and then run OCR again with the languages found.
"""

img = cv2.imread("/content/sened_1.jpg")
plt.figure(figsize=(10, 8))
plt.imshow(img)

"""The language codes used by langdetect follow ISO 639-1 codes. Here, it thinks these are turkish words"""

# !pip install langdetect
from langdetect import detect_langs

custom_config = r'-l eng+aze --psm 6'
txt = pytesseract.image_to_string(img, config=custom_config)
detect_langs(txt)

custom_config = r'-l tur --psm 6'
txt = pytesseract.image_to_string(img, config=custom_config)

print(txt)

hImg, wImg, color = img.shape
boxes = pytesseract.image_to_boxes(img)

for b in boxes.splitlines():
  b = b.split(' ')
  x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4])
  img = cv2.rectangle(img, (x, hImg - y), (w,hImg - h), (0, 255, 0), 2)
  img = cv2.putText(img, b[0], (x, hImg - y), cv2.FONT_HERSHEY_COMPLEX, 1, (50, 50, 255), 2)
plt.figure(figsize=(12, 10)) 
plt.imshow(img, 'gray')